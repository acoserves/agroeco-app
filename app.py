import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO

# --------------------------------------------------
# 0. Param√®tres g√©n√©raux
# --------------------------------------------------

META_PATH = "AGROECO_Metadata_Questions.xlsx"  # fichier de m√©tadonn√©es √† placer √† c√¥t√© de app.py

# Colonnes de contexte attendues dans la base brute Kobo
ID_COLS = ["country", "actor_category", "respondent_index"]


# --------------------------------------------------
# 1. Fonctions utilitaires
# --------------------------------------------------

@st.cache_data
def load_metadata(meta_path: str) -> pd.DataFrame:
    """Charge le fichier de m√©tadonn√©es des questions."""
    meta_df = pd.read_excel(meta_path, sheet_name="questions")
    return meta_df


def mean_excluding_zero(x: pd.Series) -> float:
    """Moyenne en excluant les 0 (0 = ne sait pas / non-r√©ponse)."""
    x = x.replace(0, np.nan)
    return x.mean()


def run_analysis(raw_df: pd.DataFrame, meta_df: pd.DataFrame):
    """
    Applique la logique AGRO ECO :
    - passage en long
    - jointure avec les m√©tadonn√©es
    - agr√©gations
    Retourne :
    - tous_les_resultats
    - resume_par_categorie
    - resume_par_pays
    """

    # V√©rifier que les colonnes de contexte sont l√†
    for col in ID_COLS:
        if col not in raw_df.columns:
            raise ValueError(f"Colonne de contexte manquante dans la base brute : {col}")

    # Liste des variables d‚Äôindicateurs issues des m√©tadonn√©es
    indicator_vars = meta_df["var_name"].dropna().unique().tolist()

    # Garder seulement celles qui existent effectivement dans la base
    indicator_vars = [v for v in indicator_vars if v in raw_df.columns]

    if len(indicator_vars) == 0:
        raise ValueError("Aucune variable d‚Äôindicateur trouv√©e dans la base brute.")

    # Conversion en num√©rique
    raw_df[indicator_vars] = raw_df[indicator_vars].apply(
        pd.to_numeric, errors="coerce"
    )

    # Passage en long : une ligne = 1 r√©pondant √ó 1 indicateur
    long_df = raw_df.melt(
        id_vars=ID_COLS,
        value_vars=indicator_vars,
        var_name="var_name",
        value_name="value"
    )

    # Jointure avec les m√©tadonn√©es
    meta_subset = meta_df[
        ["var_name", "dimension_code", "dimension_label",
         "question_index", "label", "hint"]
    ]
    long_df = long_df.merge(meta_subset, on="var_name", how="left")

    # --------------------------------------------------
    # Table 1 ‚Äì Tous les r√©sultats par indicateur
    # --------------------------------------------------
    tous_les_resultats = (
        long_df
        .groupby(
            ["country",
             "actor_category",
             "dimension_label",
             "dimension_code",
             "var_name",
             "question_index",
             "label"],
            dropna=False
        )["value"]
        .apply(mean_excluding_zero)
        .reset_index(name="mean_score")
    )

    tous_les_resultats = tous_les_resultats.sort_values(
        by=["country", "actor_category",
            "dimension_code", "question_index"]
    )

    # --------------------------------------------------
    # Table 2 ‚Äì R√©sum√© par dimension et cat√©gorie d‚Äôacteurs
    # --------------------------------------------------
    resume_par_categorie = (
        tous_les_resultats
        .groupby(
            ["country",
             "actor_category",
             "dimension_label",
             "dimension_code"],
            dropna=False
        )["mean_score"]
        .mean()
        .reset_index(name="dimension_mean")
    )

    resume_par_categorie = resume_par_categorie.sort_values(
        by=["country", "actor_category", "dimension_code"]
    )

    # --------------------------------------------------
    # Table 3 ‚Äì R√©sum√© par dimension et pays (tous acteurs confondus)
    # --------------------------------------------------
    resume_par_pays = (
        tous_les_resultats
        .groupby(
            ["country",
             "dimension_label",
             "dimension_code"],
            dropna=False
        )["mean_score"]
        .mean()
        .reset_index(name="dimension_mean")
    )

    resume_par_pays = resume_par_pays.sort_values(
        by=["country", "dimension_code"]
    )

    return tous_les_resultats, resume_par_categorie, resume_par_pays


def build_excel_bytes(tous_les_resultats: pd.DataFrame,
                      resume_par_categorie: pd.DataFrame,
                      resume_par_pays: pd.DataFrame) -> bytes:
    """
    Construit un fichier Excel en m√©moire avec les trois tables de r√©sultats.
    Retourne les bytes pour t√©l√©chargement.
    """
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        tous_les_resultats.to_excel(
            writer, sheet_name="Tous_les_resultats", index=False
        )
        resume_par_categorie.to_excel(
            writer, sheet_name="Resume_par_categorie", index=False
        )
        resume_par_pays.to_excel(
            writer, sheet_name="Resume_par_pays", index=False
        )

    output.seek(0)
    return output.getvalue()


# --------------------------------------------------
# 2. Interface Streamlit
# --------------------------------------------------

st.set_page_config(
    page_title="AGRO ECO / QTAAE ‚Äì Analyse automatique",
    layout="wide"
)

st.title("AGRO ECO / QTAAE ‚Äì Analyse automatique des donn√©es Kobo")

st.markdown(
    """
    Cet outil permet d‚Äôanalyser automatiquement une **base brute Kobo** 
    issue du questionnaire AGRO ECO / QTAAE, et de produire des r√©sultats 
    identiques (moyennes par indicateur et par dimension) √† la version Excel de l‚Äôoutil.
    
    **√âtapes :**
    1. T√©l√©verser la base brute (Excel) t√©l√©charg√©e depuis KoboCollect.  
    2. V√©rifier l‚Äôaper√ßu.  
    3. Lancer l‚Äôanalyse.  
    4. Visualiser les tableaux et quelques graphiques.  
    5. T√©l√©charger le fichier de r√©sultats (Excel).
    """
)

# Charger les m√©tadonn√©es (une seule fois)
try:
    meta_df = load_metadata(META_PATH)
except Exception as e:
    st.error(f"Erreur lors du chargement des m√©tadonn√©es ({META_PATH}) : {e}")
    st.stop()

uploaded_file = st.file_uploader(
    "T√©l√©verser la base brute Kobo (Excel)",
    type=["xlsx", "xls"]
)

if uploaded_file is not None:
    try:
        raw_df = pd.read_excel(uploaded_file)
    except Exception as e:
        st.error(f"Erreur lors de la lecture du fichier Excel : {e}")
        st.stop()

    st.subheader("Aper√ßu de la base brute")
    st.dataframe(raw_df.head())

    # Bouton pour lancer l'analyse
    if st.button("Lancer l'analyse AGRO ECO"):
        try:
            tous_les_resultats, resume_par_categorie, resume_par_pays = run_analysis(
                raw_df, meta_df
            )
        except Exception as e:
            st.error(f"Erreur lors de l'analyse : {e}")
            st.stop()

        st.success("Analyse termin√©e.")

        # --------------------------
        # TABLEAUX
        # --------------------------
        st.subheader("R√©sum√© par dimension et par pays")
        st.dataframe(resume_par_pays)

        st.subheader("R√©sum√© par dimension, pays et cat√©gorie d'acteurs")
        st.dataframe(resume_par_categorie)

        st.subheader("Tous les r√©sultats (par indicateur, pays, cat√©gorie)")
        st.dataframe(tous_les_resultats)

        # --------------------------
        # GRAPHIQUES ‚Äì PAR PAYS
        # --------------------------
        st.markdown("## Graphiques ‚Äì Dimensions par pays")

        # Tableau crois√©: lignes = dimensions, colonnes = pays
        pivot_pays = resume_par_pays.pivot(
            index="dimension_label",
            columns="country",
            values="dimension_mean"
        )
        st.bar_chart(pivot_pays)

        # --------------------------
        # GRAPHIQUES ‚Äì PAR CAT√âGORIE ET PAR PAYS
        # --------------------------
        st.markdown("## Graphiques ‚Äì Dimensions par cat√©gorie d'acteurs et par pays")

        countries = resume_par_pays["country"].dropna().unique().tolist()
        for country in countries:
            st.markdown(f"### {country}")
            dfc = resume_par_categorie[resume_par_categorie["country"] == country]
            if not dfc.empty:
                pivot_cat = dfc.pivot(
                    index="actor_category",
                    columns="dimension_label",
                    values="dimension_mean"
                ).sort_index()
                st.bar_chart(pivot_cat)

        # Export Excel
        excel_bytes = build_excel_bytes(
            tous_les_resultats, resume_par_categorie, resume_par_pays
        )

        st.download_button(
            label="üì• T√©l√©charger le fichier de r√©sultats (Excel)",
            data=excel_bytes,
            file_name="AGROECO_Results_from_Kobo.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
else:
    st.info("Veuillez t√©l√©verser un fichier Excel brut export√© de KoboCollect.")
